import requests
from bs4 import BeautifulSoup
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment
from datetime import datetime
import re
import time
from fake_useragent import UserAgent
import random

print("ğŸš€ GERÃ‡EK WEB ARAÅTIRMALI ANALÄ°Z SÄ°STEMÄ°")

class RealWebAnalyzer:
    def __init__(self):
        self.ua = UserAgent()
    
    def search_company_news(self, company, country):
        """Google News'de ÅŸirket haberlerini ara"""
        results = []
        
        try:
            headers = {
                'User-Agent': self.ua.random,
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
            }
            
            search_terms = [
                f"{company} {country} export",
                f"{company} Russia business",
                f"{company} {country} trade",
                f"{company} sanctions Russia"
            ]
            
            for term in search_terms:
                try:
                    print(f"ğŸ” AranÄ±yor: '{term}'")
                    
                    # Google arama
                    url = f"https://www.google.com/search?q={term.replace(' ', '+')}&num=5"
                    response = requests.get(url, headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        soup = BeautifulSoup(response.text, 'html.parser')
                        
                        # SonuÃ§larÄ± al
                        search_results = soup.find_all('div', class_='g')[:3]
                        
                        for i, result in enumerate(search_results):
                            try:
                                title_elem = result.find('h3')
                                if title_elem:
                                    title = title_elem.get_text()
                                    link_elem = result.find('a')
                                    if link_elem and 'href' in link_elem.attrs:
                                        link = link_elem['href']
                                        
                                        # URL'yi temizle
                                        if link.startswith('/url?q='):
                                            link = link.split('/url?q=')[1].split('&')[0]
                                        
                                        # Sayfa iÃ§eriÄŸini al
                                        page_content = self.get_page_content(link, headers)
                                        
                                        if page_content:
                                            # Analiz yap
                                            analysis = self.analyze_content(company, country, title + " " + page_content)
                                            analysis.update({
                                                'URL': link,
                                                'BAÅLIK': title,
                                                'Ä°Ã‡ERÄ°K_Ã–ZETÄ°': page_content[:200] + '...',
                                                'ARAMA_TERÄ°MÄ°': term
                                            })
                                            results.append(analysis)
                                            print(f"   âœ… {analysis['DURUM']} - %{analysis['GÃœVEN_YÃœZDESÄ°']:.1f}")
                                            
                            except Exception as e:
                                print(f"   âŒ SonuÃ§ iÅŸleme hatasÄ±: {e}")
                                continue
                    
                    time.sleep(2)  # Rate limiting
                    
                except Exception as e:
                    print(f"âŒ Arama hatasÄ±: {e}")
                    continue
            
        except Exception as e:
            print(f"âŒ Genel arama hatasÄ±: {e}")
        
        return results
    
    def get_page_content(self, url, headers):
        """Web sayfasÄ± iÃ§eriÄŸini al"""
        try:
            response = requests.get(url, headers=headers, timeout=8)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Script ve style tag'lerini temizle
                for script in soup(["script", "style"]):
                    script.decompose()
                
                text = soup.get_text()
                # Fazla boÅŸluklarÄ± temizle
                lines = (line.strip() for line in text.splitlines())
                chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                text = ' '.join(chunk for chunk in chunks if chunk)
                
                return text[:3000]  # Ä°lk 3000 karakter
                
        except Exception as e:
            print(f"   âŒ Sayfa okuma hatasÄ±: {e}")
        
        return None
    
    def analyze_content(self, company, country, text):
        """Ä°Ã§eriÄŸi analiz et"""
        try:
            text_lower = text.lower()
            company_lower = company.lower()
            country_lower = country.lower()
            
            score = 0
            reasons = []
            keywords_found = []
            
            # Åirket ve Ã¼lke eÅŸleÅŸmesi
            company_found = any(word in text_lower for word in company_lower.split() if len(word) > 2)
            country_found = country_lower in text_lower
            
            if company_found:
                score += 30
                reasons.append("Åirket ismi bulundu")
            
            if country_found:
                score += 30
                reasons.append("Ãœlke ismi bulundu")
            
            # Ticaret terimleri
            trade_terms = {
                'export': 20, 'import': 20, 'trade': 15, 'business': 15,
                'partner': 15, 'supplier': 15, 'distributor': 15,
                'shipment': 10, 'logistics': 10, 'supply': 10
            }
            
            for term, points in trade_terms.items():
                if term in text_lower:
                    score += points
                    keywords_found.append(term)
                    reasons.append(f"{term} terimi bulundu")
            
            # GTIP kodlarÄ±
            gtip_codes = self.extract_gtip_codes(text)
            
            # YaptÄ±rÄ±m riski
            yaptirim_risk = "DÃœÅÃœK"
            yaptirimli_gtip = []
            
            if country_lower in ['russia', 'rusya'] and gtip_codes:
                yasakli_gtip = ['8703', '8708', '8407', '8471', '8542']
                for code in gtip_codes:
                    if code in yasakli_gtip:
                        yaptirim_risk = "YÃœKSEK_RÄ°SK"
                        yaptirimli_gtip.append(code)
                        reasons.append(f"YasaklÄ± GTIP: {code}")
            
            # BaÄŸlam bonusu
            if company_found and country_found:
                score += 20
                reasons.append("Åirket-Ã¼lke baÄŸlamÄ± gÃ¼Ã§lÃ¼")
            
            # Skor normalizasyonu
            percentage = min(100, score)
            
            # Durum belirleme
            if yaptirim_risk == "YÃœKSEK_RÄ°SK":
                status = "YÃœKSEK_RÄ°SK"
                explanation = f"â›” YÃœKSEK RÄ°SK: {company} - {country} (%{percentage:.1f})"
            elif percentage >= 70:
                status = "YÃœKSEK_GÃœVEN"
                explanation = f"âœ… YÃœKSEK GÃœVEN: {company} - {country} (%{percentage:.1f})"
            elif percentage >= 40:
                status = "ORTA_GÃœVEN"
                explanation = f"ğŸŸ¡ ORTA GÃœVEN: {company} - {country} (%{percentage:.1f})"
            else:
                status = "DÃœÅÃœK_GÃœVEN"
                explanation = f"ğŸ”´ DÃœÅÃœK GÃœVEN: {company} - {country} (%{percentage:.1f})"
            
            return {
                'ÅÄ°RKET': company,
                'ÃœLKE': country,
                'DURUM': status,
                'GÃœVEN_YÃœZDESÄ°': percentage,
                'AI_AÃ‡IKLAMA': explanation,
                'AI_NEDENLER': ' | '.join(reasons),
                'AI_ANAHTAR_KELÄ°MELER': ', '.join(keywords_found),
                'YAPTIRIM_RISKI': yaptirim_risk,
                'TESPIT_EDILEN_GTIPLER': ', '.join(gtip_codes),
                'YAPTIRIMLI_GTIPLER': ', '.join(yaptirimli_gtip),
                'TARÄ°H': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            return {
                'ÅÄ°RKET': company,
                'ÃœLKE': country,
                'DURUM': 'HATA',
                'GÃœVEN_YÃœZDESÄ°': 0,
                'AI_AÃ‡IKLAMA': f'Analiz hatasÄ±: {str(e)}',
                'AI_NEDENLER': '',
                'AI_ANAHTAR_KELÄ°MELER': '',
                'YAPTIRIM_RISKI': 'BELÄ°RSÄ°Z',
                'TESPIT_EDILEN_GTIPLER': '',
                'YAPTIRIMLI_GTIPLER': '',
                'TARÄ°H': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def extract_gtip_codes(self, text):
        """Metinden GTIP kodlarÄ±nÄ± Ã§Ä±kar"""
        gtip_pattern = r'\b\d{4}(?:\.\d{2,4})?\b'
        codes = re.findall(gtip_pattern, text)
        
        main_codes = set()
        for code in codes:
            main_code = code.split('.')[0]
            if len(main_code) == 4:
                main_codes.add(main_code)
        
        return list(main_codes)[:5]

def run_real_analysis(company_name, country):
    """GerÃ§ek web araÅŸtÄ±rmalÄ± analiz"""
    print(f"ğŸ¯ GERÃ‡EK ANALÄ°Z: {company_name} - {country}")
    
    analyzer = RealWebAnalyzer()
    results = analyzer.search_company_news(company_name, country)
    
    # EÄŸer sonuÃ§ yoksa, temel analiz yap
    if not results:
        print("â„¹ï¸ Web sonucu bulunamadÄ±, temel analiz yapÄ±lÄ±yor...")
        basic_analysis = analyzer.analyze_content(
            company_name, 
            country, 
            f"{company_name} company business news {country} market"
        )
        basic_analysis.update({
            'URL': 'https://example.com/basic-analysis',
            'BAÅLIK': f'{company_name} Basic Business Analysis',
            'Ä°Ã‡ERÄ°K_Ã–ZETÄ°': 'Web arama sonuÃ§ bulunamadÄ±, temel analiz uygulandÄ±',
            'ARAMA_TERÄ°MÄ°': 'basic analysis'
        })
        results = [basic_analysis]
    
    print(f"âœ… GERÃ‡EK ANALÄ°Z TAMAMLANDI: {len(results)} sonuÃ§")
    return results

def create_real_excel_report(results, filename='gercek_analiz.xlsx'):
    """GerÃ§ek verili Excel raporu"""
    try:
        import pandas as pd
        
        df = pd.DataFrame(results)
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # Ana sonuÃ§lar
            df.to_excel(writer, sheet_name='GerÃ§ek Analiz SonuÃ§larÄ±', index=False)
            
            # Ã–zet
            summary_data = [{
                'ÅÄ°RKET': results[0]['ÅÄ°RKET'] if results else 'N/A',
                'ÃœLKE': results[0]['ÃœLKE'] if results else 'N/A',
                'TOPLAM_ANALÄ°Z': len(results),
                'ORTALAMA_GÃœVEN': round(df['GÃœVEN_YÃœZDESÄ°'].mean(), 1) if not df.empty else 0,
                'YÃœKSEK_RÄ°SKLÄ°': len(df[df['YAPTIRIM_RISKI'] == 'YÃœKSEK_RÄ°SK']),
                'WEB_KAYNAKLI': len(df[df['URL'] != 'https://example.com/basic-analysis']),
                'ANALÄ°Z_TARÄ°HÄ°': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }]
            pd.DataFrame(summary_data).to_excel(writer, sheet_name='Ã–zet', index=False)
        
        print(f"âœ… GERÃ‡EK Excel oluÅŸturuldu: {filename}")
        return True
        
    except Exception as e:
        print(f"âŒ Excel hatasÄ±: {e}")
        return False

# Test
if __name__ == "__main__":
    results = run_real_analysis("Ford", "Russia")
    create_real_excel_report(results)
    print("ğŸ‰ GERÃ‡EK ANALÄ°Z TAMAMLANDI!")
