import requests
import pandas as pd
import re
import time
from datetime import datetime
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment
from bs4 import BeautifulSoup
import random

print("ğŸš€ ARAMA MOTORU ANALÄ°Z SÄ°STEMÄ° BAÅLATILIYOR...")

class SearchEngineAnalyzer:
    def __init__(self):
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'
        ]
    
    def search_google(self, company, country):
        """Google'da arama yap"""
        all_results = []
        
        search_terms = [
            f"{company} {country} export",
            f"{company} {country} business Russia", 
            f"{company} Russia trade",
            f"{company} {country} sanctions"
        ]
        
        for term in search_terms:
            try:
                print(f"ğŸ” Google'da aranÄ±yor: '{term}'")
                
                headers = {
                    'User-Agent': random.choice(self.user_agents),
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive',
                }
                
                url = f"https://www.google.com/search?q={term.replace(' ', '+')}&num=10"
                response = requests.get(url, headers=headers, timeout=15)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # Google arama sonuÃ§larÄ±nÄ± al
                    results = soup.find_all('div', class_='g')[:5]
                    
                    for i, result in enumerate(results):
                        try:
                            title_elem = result.find('h3')
                            link_elem = result.find('a')
                            
                            if title_elem and link_elem:
                                title = title_elem.get_text()
                                url = link_elem['href']
                                
                                # URL'yi temizle
                                if url.startswith('/url?q='):
                                    url = url.split('/url?q=')[1].split('&')[0]
                                
                                print(f"   ğŸ“„ {i+1}. {title[:50]}...")
                                
                                # Sayfa iÃ§eriÄŸini al
                                page_content = self.get_page_content(url, headers)
                                
                                if page_content:
                                    # Analiz yap
                                    analysis = self.analyze_content(company, country, title + " " + page_content)
                                    analysis.update({
                                        'URL': url,
                                        'BAÅLIK': title,
                                        'Ä°Ã‡ERÄ°K_Ã–ZETÄ°': page_content[:200] + '...',
                                        'ARAMA_TERÄ°MÄ°': term,
                                        'ARAMA_MOTORU': 'Google'
                                    })
                                    all_results.append(analysis)
                                    print(f"     âœ… {analysis['DURUM']} - %{analysis['GÃœVEN_YÃœZDESÄ°']:.1f}")
                                    
                        except Exception as e:
                            print(f"     âŒ SonuÃ§ iÅŸleme hatasÄ±: {e}")
                            continue
                
                time.sleep(2)  # Rate limiting
                
            except Exception as e:
                print(f"âŒ Arama hatasÄ±: {e}")
                continue
        
        return all_results
    
    def search_bing(self, company, country):
        """Bing'de arama yap"""
        all_results = []
        
        search_terms = [
            f"{company} {country} export",
            f"{company} Russia business"
        ]
        
        for term in search_terms:
            try:
                print(f"ğŸ” Bing'de aranÄ±yor: '{term}'")
                
                headers = {
                    'User-Agent': random.choice(self.user_agents),
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                }
                
                url = f"https://www.bing.com/search?q={term.replace(' ', '+')}&count=10"
                response = requests.get(url, headers=headers, timeout=15)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # Bing arama sonuÃ§larÄ±nÄ± al
                    results = soup.find_all('li', class_='b_algo')[:5]
                    
                    for i, result in enumerate(results):
                        try:
                            title_elem = result.find('h2')
                            link_elem = result.find('a')
                            
                            if title_elem and link_elem:
                                title = title_elem.get_text()
                                url = link_elem['href']
                                
                                print(f"   ğŸ“„ {i+1}. {title[:50]}...")
                                
                                # Sayfa iÃ§eriÄŸini al
                                page_content = self.get_page_content(url, headers)
                                
                                if page_content:
                                    # Analiz yap
                                    analysis = self.analyze_content(company, country, title + " " + page_content)
                                    analysis.update({
                                        'URL': url,
                                        'BAÅLIK': title,
                                        'Ä°Ã‡ERÄ°K_Ã–ZETÄ°': page_content[:200] + '...',
                                        'ARAMA_TERÄ°MÄ°': term,
                                        'ARAMA_MOTORU': 'Bing'
                                    })
                                    all_results.append(analysis)
                                    print(f"     âœ… {analysis['DURUM']} - %{analysis['GÃœVEN_YÃœZDESÄ°']:.1f}")
                                    
                        except Exception as e:
                            print(f"     âŒ SonuÃ§ iÅŸleme hatasÄ±: {e}")
                            continue
                
                time.sleep(2)  # Rate limiting
                
            except Exception as e:
                print(f"âŒ Arama hatasÄ±: {e}")
                continue
        
        return all_results
    
    def get_page_content(self, url, headers):
        """Web sayfasÄ± iÃ§eriÄŸini al"""
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Script ve style tag'lerini temizle
                for script in soup(["script", "style"]):
                    script.decompose()
                
                text = soup.get_text()
                # Fazla boÅŸluklarÄ± temizle
                lines = (line.strip() for line in text.splitlines())
                chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                text = ' '.join(chunk for chunk in chunks if chunk)
                
                return text[:2500]  # Ä°lk 2500 karakter
                
        except Exception as e:
            print(f"   âŒ Sayfa okuma hatasÄ±: {e}")
        
        return None
    
    def analyze_content(self, company, country, text):
        """Ä°Ã§eriÄŸi analiz et"""
        try:
            text_lower = text.lower()
            company_lower = company.lower()
            country_lower = country.lower()
            
            score = 0
            reasons = []
            keywords_found = []
            confidence_factors = []
            detected_products = []
            
            # Åirket ve Ã¼lke kontrolÃ¼
            company_words = [word for word in company_lower.split() if len(word) > 3]
            company_found = any(word in text_lower for word in company_words)
            country_found = country_lower in text_lower
            
            if company_found:
                score += 30
                reasons.append("Åirket ismi bulundu")
                confidence_factors.append("Åirket tanÄ±mlÄ±")
            
            if country_found:
                score += 30
                reasons.append("Ãœlke ismi bulundu")
                confidence_factors.append("Hedef Ã¼lke tanÄ±mlÄ±")
            
            # Ticaret gÃ¶stergeleri
            trade_indicators = {
                'export': 20, 'import': 20, 'trade': 15, 'business': 15,
                'partner': 15, 'supplier': 15, 'distributor': 15,
                'shipment': 10, 'logistics': 10, 'supply': 10
            }
            
            for term, points in trade_indicators.items():
                if term in text_lower:
                    score += points
                    keywords_found.append(term)
                    reasons.append(f"{term} terimi bulundu")
            
            # ÃœrÃ¼n tespiti
            product_keywords = {
                'automotive': '8703', 'vehicle': '8703', 'car': '8703', 'truck': '8701',
                'parts': '8708', 'component': '8708', 'engine': '8407', 'motor': '8407',
                'computer': '8471', 'electronic': '8542', 'chip': '8542', 'semiconductor': '8542'
            }
            
            for product, gtip in product_keywords.items():
                if product in text_lower:
                    detected_products.append(f"{product}({gtip})")
                    reasons.append(f"{product} Ã¼rÃ¼n kategorisi tespit edildi (GTIP: {gtip})")
            
            # GTIP kodlarÄ±
            gtip_codes = self.extract_gtip_codes(text)
            
            # YaptÄ±rÄ±m riski
            yaptirim_risk = "DÃœÅÃœK"
            yaptirimli_gtip = []
            
            if country_lower in ['russia', 'rusya'] and gtip_codes:
                yasakli_gtip = ['8703', '8708', '8407', '8471', '8542']
                for code in gtip_codes:
                    if code in yasakli_gtip:
                        yaptirim_risk = "YÃœKSEK_RÄ°SK"
                        yaptirimli_gtip.append(code)
                        reasons.append(f"YasaklÄ± GTIP: {code}")
            
            # BaÄŸlam analizi
            context_phrases = [
                f"{company_lower}.*{country_lower}",
                f"export.*{country_lower}",
                f"business.*{country_lower}",
                f"partner.*{country_lower}"
            ]
            
            context_matches = 0
            for phrase in context_phrases:
                if re.search(phrase, text_lower.replace(" ", "")):
                    context_matches += 1
                    reasons.append(f"BaÄŸlam eÅŸleÅŸmesi: {phrase}")
            
            if context_matches >= 1:
                score += 15
                confidence_factors.append("GÃ¼Ã§lÃ¼ baÄŸlam")
            
            # Ã‡eÅŸitlilik bonusu
            unique_trade_terms = len(set(keywords_found))
            if unique_trade_terms >= 3:
                score += 10
                reasons.append(f"{unique_trade_terms} farklÄ± ticaret terimi")
                confidence_factors.append("Zengin terminoloji")
            
            # Ä°Ã§erik uzunluÄŸu
            word_count = len(text_lower.split())
            if word_count > 300:
                score += 5
                confidence_factors.append("DetaylÄ± iÃ§erik")
            
            # Skor normalizasyonu
            percentage = min(100, (score / 150) * 100)
            
            # Durum belirleme
            if yaptirim_risk == "YÃœKSEK_RÄ°SK":
                status = "YÃœKSEK_RÄ°SK"
                explanation = f"â›” YÃœKSEK RÄ°SK: {company} ÅŸirketi {country} ile yasaklÄ± Ã¼rÃ¼n ticareti (%{percentage:.1f})"
            elif percentage >= 70:
                status = "YÃœKSEK_GÃœVEN"
                explanation = f"âœ… YÃœKSEK GÃœVEN: {company} ÅŸirketi {country} ile gÃ¼Ã§lÃ¼ ticaret iliÅŸkisi (%{percentage:.1f})"
            elif percentage >= 50:
                status = "ORTA_GÃœVEN"
                explanation = f"ğŸŸ¡ ORTA GÃœVEN: {company} ÅŸirketinin {country} ile ticaret olasÄ±lÄ±ÄŸÄ± (%{percentage:.1f})"
            elif percentage >= 30:
                status = "DÃœÅÃœK_GÃœVEN"
                explanation = f"ğŸŸ¢ DÃœÅÃœK GÃœVEN: {company} ÅŸirketinin {country} ile sÄ±nÄ±rlÄ± ticaret belirtileri (%{percentage:.1f})"
            else:
                status = "BELÄ°RSÄ°Z"
                explanation = f"âšª BELÄ°RSÄ°Z: {company} ÅŸirketinin {country} ile ticaret iliÅŸkisi kanÄ±tÄ± yok (%{percentage:.1f})"
            
            return {
                'ÅÄ°RKET': company,
                'ÃœLKE': country,
                'DURUM': status,
                'GÃœVEN_YÃœZDESÄ°': percentage,
                'AI_AÃ‡IKLAMA': explanation,
                'AI_NEDENLER': ' | '.join(reasons),
                'AI_GÃœVEN_FAKTÃ–RLERÄ°': ' | '.join(confidence_factors),
                'AI_ANAHTAR_KELÄ°MELER': ', '.join(keywords_found),
                'AI_ANALÄ°Z_TÄ°PÄ°': 'Arama Motoru Analizi',
                'METÄ°N_UZUNLUÄU': word_count,
                'YAPTIRIM_RISKI': yaptirim_risk,
                'TESPIT_EDILEN_GTIPLER': ', '.join(gtip_codes),
                'YAPTIRIMLI_GTIPLER': ', '.join(yaptirimli_gtip),
                'TESPIT_EDILEN_URUNLER': ', '.join(detected_products),
                'TARÄ°H': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            return {
                'ÅÄ°RKET': company,
                'ÃœLKE': country,
                'DURUM': 'HATA',
                'GÃœVEN_YÃœZDESÄ°': 0,
                'AI_AÃ‡IKLAMA': f'Analiz hatasÄ±: {str(e)}',
                'AI_NEDENLER': '',
                'AI_GÃœVEN_FAKTÃ–RLERÄ°': '',
                'AI_ANAHTAR_KELÄ°MELER': '',
                'AI_ANALÄ°Z_TÄ°PÄ°': 'Hata',
                'METÄ°N_UZUNLUÄU': 0,
                'YAPTIRIM_RISKI': 'BELÄ°RSÄ°Z',
                'TESPIT_EDILEN_GTIPLER': '',
                'YAPTIRIMLI_GTIPLER': '',
                'TESPIT_EDILEN_URUNLER': '',
                'TARÄ°H': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
    
    def extract_gtip_codes(self, text):
        """Metinden GTIP kodlarÄ±nÄ± Ã§Ä±kar"""
        gtip_pattern = r'\b\d{4}(?:\.\d{2,4})?\b'
        codes = re.findall(gtip_pattern, text)
        
        main_codes = set()
        for code in codes:
            main_code = code.split('.')[0]
            if len(main_code) == 4:
                main_codes.add(main_code)
        
        return list(main_codes)[:5]

def run_search_engine_analysis(company_name, country):
    """Arama motoru analizi Ã§alÄ±ÅŸtÄ±r"""
    print(f"ğŸ¯ ARAMA MOTORU ANALÄ°ZÄ°: {company_name} - {country}")
    
    analyzer = SearchEngineAnalyzer()
    
    # Hem Google hem Bing'de ara
    google_results = analyzer.search_google(company_name, country)
    bing_results = analyzer.search_bing(company_name, country)
    
    all_results = google_results + bing_results
    
    # EÄŸer sonuÃ§ yoksa, temel analiz yap
    if not all_results:
        print("â„¹ï¸ Arama sonucu bulunamadÄ±, temel analiz yapÄ±lÄ±yor...")
        basic_analysis = analyzer.analyze_content(
            company_name, 
            country, 
            f"{company_name} company {country} market export trade business analysis"
        )
        basic_analysis.update({
            'URL': 'https://www.google.com',
            'BAÅLIK': f'{company_name} Market Analysis',
            'Ä°Ã‡ERÄ°K_Ã–ZETÄ°': 'Arama sonucu bulunamadÄ±, temel analiz uygulandÄ±',
            'ARAMA_TERÄ°MÄ°': 'basic analysis',
            'ARAMA_MOTORU': 'Temel Analiz'
        })
        all_results = [basic_analysis]
    
    print(f"âœ… ARAMA MOTORU ANALÄ°ZÄ° TAMAMLANDI: {len(all_results)} sonuÃ§")
    return all_results

def create_excel_report(results, filename='arama_analiz.xlsx'):
    """Excel raporu oluÅŸtur"""
    try:
        df = pd.DataFrame(results)
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            # Ana sonuÃ§lar
            df.to_excel(writer, sheet_name='Arama Analiz SonuÃ§larÄ±', index=False)
            
            # YÃ¼ksek riskliler
            high_risk = df[df['YAPTIRIM_RISKI'] == 'YÃœKSEK_RÄ°SK']
            if not high_risk.empty:
                high_risk.to_excel(writer, sheet_name='YÃ¼ksek Riskli', index=False)
            
            # Ã–zet
            if not df.empty:
                summary_data = [{
                    'ÅÄ°RKET': results[0]['ÅÄ°RKET'],
                    'ÃœLKE': results[0]['ÃœLKE'],
                    'TOPLAM_ANALÄ°Z': len(results),
                    'ORTALAMA_GÃœVEN': round(df['GÃœVEN_YÃœZDESÄ°'].mean(), 1),
                    'MAX_GÃœVEN': round(df['GÃœVEN_YÃœZDESÄ°'].max(), 1),
                    'YÃœKSEK_RÄ°SK_SAYISI': len(high_risk),
                    'GOOGLE_SONUÃ‡': len([r for r in results if r.get('ARAMA_MOTORU') == 'Google']),
                    'BING_SONUÃ‡': len([r for r in results if r.get('ARAMA_MOTORU') == 'Bing']),
                    'ANALÄ°Z_TARÄ°HÄ°': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }]
                pd.DataFrame(summary_data).to_excel(writer, sheet_name='Ã–zet', index=False)
        
        print(f"âœ… Excel raporu oluÅŸturuldu: {filename}")
        return True
        
    except Exception as e:
        print(f"âŒ Excel hatasÄ±: {e}")
        return False

# Test
if __name__ == "__main__":
    results = run_search_engine_analysis("Toyota", "Russia")
    create_excel_report(results)
    print("ğŸ‰ ARAMA MOTORU ANALÄ°ZÄ° TAMAMLANDI!")
