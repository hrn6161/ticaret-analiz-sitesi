import requests
from bs4 import BeautifulSoup
import time
import random
import re
from openpyxl import Workbook
from openpyxl.styles import Font
import sys
import logging
import os
from datetime import datetime

print("ğŸš€ OPTÄ°MÄ°ZE AKILLI CRAWLER ANALÄ°Z SÄ°STEMÄ° BAÅLATILIYOR...")

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'analysis_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)

class Config:
    def __init__(self):
        self.MAX_RESULTS = 3  # Daha az sonuÃ§
        self.REQUEST_TIMEOUT = 15
        self.RETRY_ATTEMPTS = 2
        self.MAX_GTIP_CHECK = 3  # Sadece ilk 3 GTIP'i kontrol et
        self.USER_AGENTS = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        ]

class SmartCrawler:
    def __init__(self, config):
        self.config = config
    
    def smart_crawl(self, url, target_country):
        """AkÄ±llÄ± crawl - hÄ±zlÄ± ve etkili"""
        print(f"   ğŸŒ Crawl: {url[:60]}...")
        
        # 1. Deneme: Basit requests
        result = self._try_request(url, target_country)
        if result['status_code'] == 200:
            return result
        
        # 2. Deneme: GeliÅŸmiÅŸ headers
        result = self._try_advanced(url, target_country)
        if result['status_code'] == 200:
            return result
        
        print(f"   âš ï¸  TÃ¼m yÃ¶ntemler baÅŸarÄ±sÄ±z")
        return {'country_found': False, 'gtip_codes': [], 'content_preview': '', 'status_code': 'FAILED'}
    
    def _try_request(self, url, target_country):
        """Basit request"""
        try:
            headers = {'User-Agent': random.choice(self.config.USER_AGENTS)}
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                return self._parse_content(response.text, target_country, response.status_code)
        except Exception as e:
            print(f"   âŒ Basit request hatasÄ±: {e}")
        return {'country_found': False, 'gtip_codes': [], 'content_preview': '', 'status_code': 'ERROR'}
    
    def _try_advanced(self, url, target_country):
        """GeliÅŸmiÅŸ headers"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            }
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                return self._parse_content(response.text, target_country, response.status_code)
        except Exception as e:
            print(f"   âŒ GeliÅŸmiÅŸ request hatasÄ±: {e}")
        return {'country_found': False, 'gtip_codes': [], 'content_preview': '', 'status_code': 'ERROR'}
    
    def _parse_content(self, html, target_country, status_code):
        """HÄ±zlÄ± iÃ§erik analizi"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            text_content = soup.get_text()
            text_lower = text_content.lower()
            
            # Ãœlke kontrolÃ¼
            country_found = target_country.lower() in text_lower
            
            # GTIP kodlarÄ±
            gtip_codes = self.extract_gtip_codes(text_content)
            
            print(f"   ğŸ” Sayfa analizi: Ãœlke={country_found}, GTIP={gtip_codes[:5]}")  # Sadece ilk 5
            
            return {
                'country_found': country_found,
                'gtip_codes': gtip_codes,
                'content_preview': text_content[:300] + "..." if len(text_content) > 300 else text_content,
                'status_code': status_code
            }
        except Exception as e:
            print(f"   âŒ Parse hatasÄ±: {e}")
            return {'country_found': False, 'gtip_codes': [], 'content_preview': '', 'status_code': 'PARSE_ERROR'}
    
    def extract_gtip_codes(self, text):
        """GTIP kodlarÄ±nÄ± Ã§Ä±kar"""
        patterns = [
            r'\b\d{4}\.?\d{0,4}\b',
            r'\bHS\s?CODE\s?:?\s?(\d{4,8})\b',
            r'\bGTIP\s?:?\s?(\d{4,8})\b',
            r'\bH\.S\.\s?CODE?\s?:?\s?(\d{4,8})\b',
        ]
        
        all_codes = set()
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    match = match[0]
                code = re.sub(r'[^\d]', '', match)
                if len(code) >= 4:
                    all_codes.add(code[:4])
        
        # 4 haneli sayÄ±larÄ± kontrol et (GTIP aralÄ±ÄŸÄ±nda mÄ±)
        number_pattern = r'\b\d{4}\b'
        numbers = re.findall(number_pattern, text)
        
        for num in numbers:
            if num.isdigit():
                num_int = int(num)
                # Ã–nemli GTIP aralÄ±klarÄ±
                gtip_ranges = [
                    (8400, 8600), (8700, 8900), (9000, 9300), 
                    (2800, 2900), (8470, 8480), (8500, 8520),
                    (8540, 8550), (4016, 4016), (8708, 8708)
                ]
                for start, end in gtip_ranges:
                    if start <= num_int <= end:
                        all_codes.add(num)
                        break
        
        return list(all_codes)[:10]  # Maksimum 10 kod

class FastSearcher:
    def __init__(self, config):
        self.config = config
    
    def fast_search(self, query, max_results=3):
        """HÄ±zlÄ± arama"""
        try:
            print(f"   ğŸ” DuckDuckGo: {query}")
            
            headers = {'User-Agent': random.choice(self.config.USER_AGENTS)}
            url = "https://html.duckduckgo.com/html/"
            data = {'q': query, 'b': '', 'kl': 'us-en'}
            
            response = requests.post(url, data=data, headers=headers, timeout=15)
            
            if response.status_code == 200:
                results = self.parse_results(response.text, max_results)
                print(f"   âœ… {len(results)} sonuÃ§ bulundu")
                return results
            else:
                print(f"   âŒ DuckDuckGo hatasÄ±: {response.status_code}")
                return []
        except Exception as e:
            print(f"   âŒ Arama hatasÄ±: {e}")
            return []
    
    def parse_results(self, html, max_results):
        """SonuÃ§larÄ± parse et"""
        soup = BeautifulSoup(html, 'html.parser')
        results = []
        
        for div in soup.find_all('div', class_='result')[:max_results]:
            try:
                title_elem = div.find('a', class_='result__a')
                if not title_elem:
                    continue
                    
                title = title_elem.get_text(strip=True)
                url = title_elem.get('href')
                
                # URL redirect
                if url and '//duckduckgo.com/l/' in url:
                    try:
                        redirect_response = requests.get(url, timeout=5, allow_redirects=True)
                        url = redirect_response.url
                    except:
                        pass
                
                snippet_elem = div.find('a', class_='result__snippet')
                snippet = snippet_elem.get_text(strip=True) if snippet_elem else ""
                
                if url and url.startswith('//'):
                    url = 'https:' + url
                
                results.append({
                    'title': title,
                    'url': url,
                    'snippet': snippet,
                    'full_text': f"{title} {snippet}"
                })
                
                print(f"      ğŸ“„ Bulunan: {title[:60]}...")
                
            except Exception as e:
                print(f"      âŒ SonuÃ§ parse hatasÄ±: {e}")
                continue
        
        return results

class QuickEURLexChecker:
    def __init__(self, config):
        self.config = config
        self.sanction_cache = {}  # Ã–nbellek iÃ§in
    
    def quick_check_gtip(self, gtip_codes):
        """HÄ±zlÄ± GTIP kontrolÃ¼ - sadece ilk 3'Ã¼"""
        if not gtip_codes:
            return []
            
        sanctioned_codes = []
        checked_codes = gtip_codes[:self.config.MAX_GTIP_CHECK]  # Sadece ilk 3
        
        print(f"   ğŸ” EUR-Lex kontrolÃ¼: {checked_codes}")
        
        for gtip_code in checked_codes:
            # Ã–nbellekte var mÄ±?
            if gtip_code in self.sanction_cache:
                if self.sanction_cache[gtip_code]:
                    sanctioned_codes.append(gtip_code)
                    print(f"   â›” Ã–nbellekten yaptÄ±rÄ±mlÄ±: {gtip_code}")
                continue
                
            try:
                # HÄ±zlÄ± kontrol - sadece 1 sorgu
                url = "https://eur-lex.europa.eu/search.html"
                params = {
                    'text': f'"{gtip_code}" sanction prohibited',
                    'type': 'advanced',
                    'lang': 'en'
                }
                
                response = requests.get(url, params=params, timeout=8)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    content = soup.get_text().lower()
                    
                    # Basit kontrol
                    sanction_terms = ['prohibited', 'banned', 'sanction', 'restricted']
                    found_sanction = any(term in content for term in sanction_terms)
                    
                    if found_sanction:
                        sanctioned_codes.append(gtip_code)
                        self.sanction_cache[gtip_code] = True
                        print(f"   â›” YaptÄ±rÄ±mlÄ± kod: {gtip_code}")
                    else:
                        self.sanction_cache[gtip_code] = False
                        print(f"   âœ… Kod temiz: {gtip_code}")
                else:
                    print(f"   âŒ EUR-Lex hatasÄ±: {response.status_code}")
                
            except Exception as e:
                print(f"   âŒ EUR-Lex kontrol hatasÄ±: {e}")
                continue
        
        return sanctioned_codes

class OptimizedTradeAnalyzer:
    def __init__(self, config):
        self.config = config
        self.searcher = FastSearcher(config)
        self.crawler = SmartCrawler(config)
        self.eur_lex_checker = QuickEURLexChecker(config)
    
    def optimized_analyze(self, company, country):
        """Optimize edilmiÅŸ analiz - timeout Ã¶ncelikli"""
        print(f"ğŸ¤– OPTÄ°MÄ°ZE ANALÄ°Z BAÅLATILIYOR: {company} â†” {country}")
        
        # Sadece 2 ana sorgu
        search_queries = [
            f"{company} {country} export",
            f"{company} {country} business"
        ]
        
        all_results = []
        
        for i, query in enumerate(search_queries, 1):
            try:
                print(f"\nğŸ” Sorgu {i}/{len(search_queries)}: {query}")
                
                search_results = self.searcher.fast_search(query, self.config.MAX_RESULTS)
                
                if not search_results:
                    print(f"   âš ï¸ Bu sorgu iÃ§in sonuÃ§ bulunamadÄ±")
                    continue
                
                for j, result in enumerate(search_results, 1):
                    print(f"   ğŸ“„ SonuÃ§ {j} analiz ediliyor: {result['title'][:50]}...")
                    
                    # HÄ±zlÄ± crawl
                    crawl_result = self.crawler.smart_crawl(result['url'], country)
                    
                    # Snippet'ten GTIP Ã§Ä±kar
                    if not crawl_result['gtip_codes']:
                        snippet_gtips = self.crawler.extract_gtip_codes(result['full_text'])
                        if snippet_gtips:
                            crawl_result['gtip_codes'] = snippet_gtips
                            print(f"   ğŸ” Snippet'ten GTIP Ã§Ä±karÄ±ldÄ±: {snippet_gtips}")
                    
                    # HÄ±zlÄ± EUR-Lex kontrol (sadece ilk 3 GTIP)
                    sanctioned_gtips = []
                    if crawl_result['gtip_codes']:
                        print(f"   ğŸ” HÄ±zlÄ± EUR-Lex kontrolÃ¼ yapÄ±lÄ±yor...")
                        sanctioned_gtips = self.eur_lex_checker.quick_check_gtip(crawl_result['gtip_codes'])
                    
                    # SonuÃ§ oluÅŸtur
                    analysis = self.create_analysis_result(
                        company, country, result, crawl_result, sanctioned_gtips
                    )
                    
                    all_results.append(analysis)
                
                # KÄ±sa bekleme
                if i < len(search_queries):
                    delay = 1
                    print(f"   â³ {delay} saniye bekleniyor...")
                    time.sleep(delay)
                
            except Exception as e:
                print(f"   âŒ Sorgu hatasÄ±: {e}")
                continue
        
        return all_results
    
    def create_analysis_result(self, company, country, search_result, crawl_result, sanctioned_gtips):
        """Analiz sonucu oluÅŸtur"""
        
        if sanctioned_gtips:
            status = "YAPTIRIMLI_YÃœKSEK_RISK"
            explanation = f"â›” YÃœKSEK RÄ°SK: {company} ÅŸirketi {country} ile yaptÄ±rÄ±mlÄ± Ã¼rÃ¼n ticareti yapÄ±yor"
            ai_tavsiye = f"â›” ACÄ°L DURUM! Bu Ã¼rÃ¼nlerin {country.upper()} ihracÄ± YASAKTIR: {', '.join(sanctioned_gtips)}"
            risk_level = "YÃœKSEK"
        elif crawl_result['country_found'] and crawl_result['gtip_codes']:
            status = "RISK_VAR"
            explanation = f"ğŸŸ¡ RÄ°SK VAR: {company} ÅŸirketi {country} ile ticaret baÄŸlantÄ±sÄ± bulundu"
            ai_tavsiye = f"Ticaret baÄŸlantÄ±sÄ± doÄŸrulandÄ±. GTIP kodlarÄ±: {', '.join(crawl_result['gtip_codes'][:3])}"
            risk_level = "ORTA"
        elif crawl_result['country_found']:
            status = "Ä°LÄ°ÅKÄ°_VAR"
            explanation = f"ğŸŸ¢ Ä°LÄ°ÅKÄ° VAR: {company} ÅŸirketi {country} ile baÄŸlantÄ±lÄ±"
            ai_tavsiye = "Ticaret baÄŸlantÄ±sÄ± bulundu"
            risk_level = "DÃœÅÃœK"
        else:
            status = "TEMIZ"
            explanation = f"âœ… TEMÄ°Z: {company} ÅŸirketinin {country} ile ticaret baÄŸlantÄ±sÄ± bulunamadÄ±"
            ai_tavsiye = "Ticaret baÄŸlantÄ±sÄ± bulunamadÄ±"
            risk_level = "YOK"
        
        return {
            'ÅÄ°RKET': company,
            'ÃœLKE': country,
            'DURUM': status,
            'AI_AÃ‡IKLAMA': explanation,
            'AI_TAVSIYE': ai_tavsiye,
            'YAPTIRIM_RISKI': risk_level,
            'TESPIT_EDILEN_GTIPLER': ', '.join(crawl_result['gtip_codes'][:5]),  # Sadece ilk 5
            'YAPTIRIMLI_GTIPLER': ', '.join(sanctioned_gtips),
            'ULKE_BAGLANTISI': 'EVET' if crawl_result['country_found'] else 'HAYIR',
            'BAÅLIK': search_result['title'],
            'URL': search_result['url'],
            'Ã–ZET': search_result['snippet'],
            'STATUS_CODE': crawl_result.get('status_code', 'N/A'),
            'CRAWLER_TIPI': 'OPTÄ°MÄ°ZE_CRAWLER'
        }

def create_quick_excel_report(results, company, country):
    """HÄ±zlÄ± Excel raporu"""
    try:
        filename = f"{company.replace(' ', '_')}_{country}_optimize_analiz.xlsx"
        
        wb = Workbook()
        ws = wb.active
        ws.title = "Optimize Analiz SonuÃ§larÄ±"
        
        headers = [
            'ÅÄ°RKET', 'ÃœLKE', 'DURUM', 'YAPTIRIM_RISKI', 'ULKE_BAGLANTISI',
            'TESPIT_EDILEN_GTIPLER', 'YAPTIRIMLI_GTIPLER', 'AI_AÃ‡IKLAMA', 'AI_TAVSIYE',
            'BAÅLIK', 'URL', 'CRAWLER_TIPI'
        ]
        
        for col, header in enumerate(headers, 1):
            ws.cell(row=1, column=col, value=header).font = Font(bold=True)
        
        for row, result in enumerate(results, 2):
            ws.cell(row=row, column=1, value=str(result.get('ÅÄ°RKET', '')))
            ws.cell(row=row, column=2, value=str(result.get('ÃœLKE', '')))
            ws.cell(row=row, column=3, value=str(result.get('DURUM', '')))
            ws.cell(row=row, column=4, value=str(result.get('YAPTIRIM_RISKI', '')))
            ws.cell(row=row, column=5, value=str(result.get('ULKE_BAGLANTISI', '')))
            ws.cell(row=row, column=6, value=str(result.get('TESPIT_EDILEN_GTIPLER', '')))
            ws.cell(row=row, column=7, value=str(result.get('YAPTIRIMLI_GTIPLER', '')))
            ws.cell(row=row, column=8, value=str(result.get('AI_AÃ‡IKLAMA', '')))
            ws.cell(row=row, column=9, value=str(result.get('AI_TAVSIYE', '')))
            ws.cell(row=row, column=10, value=str(result.get('BAÅLIK', '')))
            ws.cell(row=row, column=11, value=str(result.get('URL', '')))
            ws.cell(row=row, column=12, value=str(result.get('CRAWLER_TIPI', '')))
        
        for column in ws.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            ws.column_dimensions[column_letter].width = adjusted_width
        
        wb.save(filename)
        print(f"âœ… Excel raporu oluÅŸturuldu: {filename}")
        return filename
        
    except Exception as e:
        print(f"âŒ Excel rapor oluÅŸturma hatasÄ±: {e}")
        return None

def display_results(results, company, country):
    """SonuÃ§larÄ± ekranda gÃ¶ster"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š OPTÄ°MÄ°ZE ANALÄ°Z SONUÃ‡LARI: {company} â†” {country}")
    print(f"{'='*80}")
    
    if not results:
        print("âŒ Analiz sonucu bulunamadÄ±!")
        return
    
    total_results = len(results)
    high_risk_count = len([r for r in results if r.get('YAPTIRIM_RISKI') == 'YÃœKSEK'])
    medium_risk_count = len([r for r in results if r.get('YAPTIRIM_RISKI') == 'ORTA'])
    country_connection_count = len([r for r in results if r.get('ULKE_BAGLANTISI') == 'EVET'])
    
    print(f"\nğŸ“ˆ Ã–ZET:")
    print(f"   â€¢ Toplam SonuÃ§: {total_results}")
    print(f"   â€¢ Ãœlke BaÄŸlantÄ±sÄ±: {country_connection_count}")
    print(f"   â€¢ YÃœKSEK YaptÄ±rÄ±m Riski: {high_risk_count}")
    print(f"   â€¢ ORTA Risk: {medium_risk_count}")
    print(f"   â€¢ Crawler Tipi: OPTÄ°MÄ°ZE CRAWLER (25s hedef)")
    
    if high_risk_count > 0:
        print(f"\nâš ï¸  KRÄ°TÄ°K YAPTIRIM UYARISI:")
        for result in results:
            if result.get('YAPTIRIM_RISKI') == 'YÃœKSEK':
                print(f"   ğŸ”´ {result.get('BAÅLIK', '')[:60]}...")
                print(f"      YasaklÄ± GTIP: {result.get('YAPTIRIMLI_GTIPLER', '')}")
    
    for i, result in enumerate(results, 1):
        print(f"\nğŸ” SONUÃ‡ {i}:")
        print(f"   ğŸ“ BaÅŸlÄ±k: {result.get('BAÅLIK', 'N/A')}")
        print(f"   ğŸŒ URL: {result.get('URL', 'N/A')}")
        print(f"   ğŸ“‹ Ã–zet: {result.get('Ã–ZET', 'N/A')[:100]}...")
        print(f"   ğŸ¯ Durum: {result.get('DURUM', 'N/A')}")
        print(f"   âš ï¸  YaptÄ±rÄ±m Riski: {result.get('YAPTIRIM_RISKI', 'N/A')}")
        print(f"   ğŸ”— Ãœlke BaÄŸlantÄ±sÄ±: {result.get('ULKE_BAGLANTISI', 'N/A')}")
        print(f"   ğŸ” GTIP KodlarÄ±: {result.get('TESPIT_EDILEN_GTIPLER', 'Yok')}")
        if result.get('YAPTIRIMLI_GTIPLER'):
            print(f"   ğŸš« YasaklÄ± GTIP: {result.get('YAPTIRIMLI_GTIPLER', '')}")
        print(f"   ğŸ“Š Status Code: {result.get('STATUS_CODE', 'N/A')}")
        print(f"   ğŸ¤– Crawler: {result.get('CRAWLER_TIPI', 'N/A')}")
        print(f"   ğŸ’¡ AÃ§Ä±klama: {result.get('AI_AÃ‡IKLAMA', 'N/A')}")
        print(f"   ğŸ’­ Tavsiye: {result.get('AI_TAVSIYE', 'N/A')}")
        print(f"   {'â”€'*60}")

def main():
    print("ğŸ“Š OPTÄ°MÄ°ZE CRAWLER ANALÄ°Z SÄ°STEMÄ°")
    print("âš¡ Ã–ZELLÄ°K: HÄ±zlÄ± EUR-Lex + 3 GTIP Limit + Ã–nbellek")
    print("ğŸ¯ HEDEF: 25 Saniye AltÄ±nda Tamamlama")
    print("ğŸ’¡ AVANTAJ: Timeout sorunu yok, yÃ¼ksek baÅŸarÄ± oranÄ±\n")
    
    # YapÄ±landÄ±rma
    config = Config()
    analyzer = OptimizedTradeAnalyzer(config)
    
    # Manuel giriÅŸ
    company = input("Åirket adÄ±nÄ± girin: ").strip()
    country = input("Ãœlke adÄ±nÄ± girin: ").strip()
    
    if not company or not country:
        print("âŒ Åirket ve Ã¼lke bilgisi gereklidir!")
        return
    
    print(f"\nğŸš€ OPTÄ°MÄ°ZE ANALÄ°Z BAÅLATILIYOR: {company} â†” {country}")
    print("â³ 2 sorgu ile hÄ±zlÄ± arama yapÄ±lÄ±yor...")
    print("   Optimize crawler ile site analizi...")
    print("   HÄ±zlÄ± EUR-Lex kontrolÃ¼ (max 3 GTIP)...")
    print("   Hedef: 25 saniye altÄ±nda tamamlama!\n")
    
    start_time = time.time()
    results = analyzer.optimized_analyze(company, country)
    execution_time = time.time() - start_time
    
    if results:
        # SonuÃ§larÄ± gÃ¶ster
        display_results(results, company, country)
        
        # Excel raporu oluÅŸtur
        filename = create_quick_excel_report(results, company, country)
        
        if filename:
            print(f"\nâœ… Excel raporu oluÅŸturuldu: {filename}")
            print(f"â±ï¸  Toplam Ã§alÄ±ÅŸma sÃ¼resi: {execution_time:.2f} saniye")
            
            if execution_time > 25:
                print("âš ï¸  UYARI: Analiz 25 saniyeyi aÅŸtÄ±!")
            else:
                print("âœ… BAÅARILI: Analiz 25 saniye altÄ±nda tamamlandÄ±!")
            
            # Excel aÃ§ma seÃ§eneÄŸi
            try:
                open_excel = input("\nğŸ“‚ Excel dosyasÄ±nÄ± ÅŸimdi aÃ§mak ister misiniz? (e/h): ").strip().lower()
                if open_excel == 'e':
                    if os.name == 'nt':  # Windows
                        os.system(f'start excel "{filename}"')
                    elif os.name == 'posix':  # macOS/Linux
                        os.system(f'open "{filename}"' if sys.platform == 'darwin' else f'xdg-open "{filename}"')
                    print("ğŸ“‚ Excel dosyasÄ± aÃ§Ä±lÄ±yor...")
            except Exception as e:
                print(f"âš ï¸  Dosya otomatik aÃ§Ä±lamadÄ±: {e}")
                print(f"ğŸ“ LÃ¼tfen manuel olarak aÃ§Ä±n: {filename}")
        else:
            print("âŒ Excel raporu oluÅŸturulamadÄ±!")
    else:
        print("âŒ Analiz sonucu bulunamadÄ±!")

if __name__ == "__main__":
    main()
